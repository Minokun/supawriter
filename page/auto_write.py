import streamlit as st
import sys
import logging
import os
import requests
import uuid
from pathlib import Path
from utils.searxng_utils import Search, llm_task, chat, parse_outline_json
import utils.prompt_template as pt
from utils.image_utils import download_image, get_image_save_directory
import concurrent.futures
import asyncio
import nest_asyncio
from settings import LLM_MODEL, ARTICLE_TRANSFORMATIONS, HTML_NGINX_BASE_URL
from utils.auth_decorator import require_auth
from utils.auth import get_current_user
from utils.history_utils import add_history_record, load_user_history
from page import transform_article
from utils.embedding_utils import create_faiss_index, get_embedding_instance
import streamlit.components.v1 as components
import os

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

@require_auth
def main():


    # åº”ç”¨nest_asyncio
    nest_asyncio.apply()
    # åˆ‡æ¢åˆ°ProactorEventLoop
    if st.runtime.exists() and sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

    # åˆå§‹åŒ–æˆ–é‡ç½®è¿è¡ŒçŠ¶æ€
    if "run_status" not in st.session_state:
        st.session_state.run_status = False
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®run_statusï¼ˆå½“é¡µé¢åˆ·æ–°ä½†ä¸æ˜¯é€šè¿‡rerunè§¦å‘æ—¶ï¼‰
    if not st.session_state.get('_is_rerun', False):
        st.session_state.run_status = False
        
    # ä½¿ç”¨st.cache_resourceè£…é¥°å™¨æ¥ç¼“å­˜FAISSç´¢å¼•å’ŒEmbeddingå®ä¾‹
    # æ·»åŠ TTL=10ç§’ï¼Œç¡®ä¿ç´¢å¼•æ¯10ç§’åˆ·æ–°ä¸€æ¬¡
    @st.cache_resource(show_spinner="åŠ è½½FAISSç´¢å¼•å’ŒEmbeddingæ¨¡å‹...")
    def get_cached_resources(force_refresh=False):
        """è·å–ç¼“å­˜çš„FAISSç´¢å¼•å’ŒEmbeddingå®ä¾‹ï¼Œä¼˜å…ˆä»ç£ç›˜åŠ è½½
        
        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶ä»ç£ç›˜é‡æ–°åŠ è½½ç´¢å¼•ï¼Œå³ä½¿ç¼“å­˜æœ‰æ•ˆ
        """
        logger.info(f"è°ƒç”¨get_cached_resourcesï¼Œforce_refresh={force_refresh}")
        try:
            # å¯¼å…¥å‡½æ•°æ”¾åœ¨è¿™é‡Œï¼Œç¡®ä¿å®ƒä»¬åœ¨ä½¿ç”¨å‰å·²ç»è¢«æ­£ç¡®å¯¼å…¥
            from utils.embedding_utils import create_faiss_index, get_embedding_instance
            import time
            
            # å®šä¹‰ç´¢å¼•ç›®å½• - ä¸grab_html_content.pyä¸­ä½¿ç”¨åŒä¸€ç›®å½•
            index_dir = 'data/faiss'
            index_path = f"{index_dir}/index.faiss"
            data_path = f"{index_dir}/index_data.pkl"
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            import os
            os.makedirs(index_dir, exist_ok=True)
            
            # ç¬¬ä¸€æ¬¡åŠ è½½æ—¶ï¼Œè®¾ç½®æ¸…é™¤æ ‡å¿—
            if 'first_load' not in st.session_state:
                st.session_state.first_load = True
                st.session_state.should_clear_index = True
                logger.info("é¦–æ¬¡åŠ è½½ï¼Œè®¾ç½®æ¸…é™¤ç´¢å¼•æ ‡å¿—")
            
            # åœ¨ä»¥ä¸‹æƒ…å†µä¸‹æ¸…é™¤ç´¢å¼•ï¼š
            # 1. å¼ºåˆ¶åˆ·æ–°ä¸”should_clear_indexæ ‡å¿—ä¸ºTrue
            # 2. é¦–æ¬¡åŠ è½½
            should_delete_files = (force_refresh and st.session_state.get('should_clear_index', False)) or st.session_state.get('first_load', False)
            
            if should_delete_files:
                # æ¸…é™¤å½“å‰å‡½æ•°çš„ç¼“å­˜
                get_cached_resources.clear()
                logger.info("æ¸…é™¤FAISSç´¢å¼•ç¼“å­˜")
                
                # åˆ é™¤ç£ç›˜ä¸Šçš„ç´¢å¼•æ–‡ä»¶
                if os.path.exists(index_path):
                    logger.info(f"åˆ é™¤ç°æœ‰ç´¢å¼•æ–‡ä»¶: {index_path}")
                    try:
                        os.remove(index_path)
                    except Exception as e:
                        logger.error(f"åˆ é™¤ç´¢å¼•æ–‡ä»¶å¤±è´¥: {str(e)}")
                        
                if os.path.exists(data_path):
                    logger.info(f"åˆ é™¤ç°æœ‰æ•°æ®æ–‡ä»¶: {data_path}")
                    try:
                        os.remove(data_path)
                    except Exception as e:
                        logger.error(f"åˆ é™¤æ•°æ®æ–‡ä»¶å¤±è´¥: {str(e)}")
                
                # é‡ç½®çŠ¶æ€æ ‡å¿—
                st.session_state.should_clear_index = False
                st.session_state.first_load = False
                logger.info("é‡ç½®æ¸…ç©ºç´¢å¼•çŠ¶æ€æ ‡å¿—")
            elif force_refresh:
                logger.info("è¯·æ±‚å¼ºåˆ¶åˆ·æ–°ï¼Œä½†should_clear_indexæ ‡å¿—æœªè®¾ç½®ï¼Œä»…åˆ·æ–°ç¼“å­˜")
                get_cached_resources.clear()  # ä»ç„¶æ¸…é™¤ç¼“å­˜ï¼Œä½†ä¸åˆ é™¤æ–‡ä»¶
                
            # è®°å½•å½“å‰æ—¶é—´ï¼Œç”¨äºè°ƒè¯•ç¼“å­˜åˆ·æ–°æœºåˆ¶
            current_time = time.strftime("%H:%M:%S", time.localtime())
            logger.info(f"åœ¨ {current_time} åŠ è½½FAISSç´¢å¼•")
            
            # å°è¯•ä»ç£ç›˜åŠ è½½FAISSç´¢å¼•ï¼Œæˆ–åˆ›å»ºæ–°çš„ç©ºç´¢å¼•
            faiss_index = create_faiss_index(load_from_disk=True, index_dir=index_dir)
            embedding_instance = get_embedding_instance()
            
            # å¦‚æœç´¢å¼•ä¸ºç©ºï¼Œè®°å½•ä¸€ä¸ªè­¦å‘Šä½†ä»ç„¶ä½¿ç”¨å®ƒ
            if faiss_index.get_size() == 0:
                logger.warning("FAISSç´¢å¼•ä¸ºç©ºï¼Œå¯èƒ½æ²¡æœ‰å›¾ç‰‡æ•°æ®æˆ–æœªæ­£ç¡®åŠ è½½")
            else:
                logger.info(f"ä»ç£ç›˜æˆåŠŸåŠ è½½FAISSç´¢å¼•ï¼ŒåŒ…å« {faiss_index.get_size()} æ¡å›¾ç‰‡æ•°æ®")
                
            return faiss_index, embedding_instance
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–FAISSç´¢å¼•å¤±è´¥: {str(e)}")
            st.error(f"åˆå§‹åŒ–FAISSç´¢å¼•å¤±è´¥: {str(e)}")
            return None, None
    
    # è·å–ç¼“å­˜çš„èµ„æº
    # å°†get_cached_resourceså‡½æ•°å­˜å‚¨åœ¨session_stateä¸­ï¼Œä»¥ä¾¾grab_html_content.pyå¯ä»¥ä½¿ç”¨
    st.session_state.get_cached_resources = get_cached_resources
    faiss_index, embedding_instance = get_cached_resources()

    with st.sidebar:
        st.title("è¶…çº§å†™æ‰‹é…ç½®é¡¹ï¼š")
        model_type = st.selectbox('è¯·é€‰æ‹©æ¨¡å‹ä¾›åº”å•†', list(LLM_MODEL.keys()), key=1)
        model_name = st.selectbox('è¯·é€‰æ‹©æ¨¡å‹åç§°', LLM_MODEL[model_type]['model'], key=0)
        with st.form(key='my_form'):
            text_input = st.text_input(label='è¯·å¡«å†™æ–‡ç« çš„ä¸»é¢˜', help='æ–‡ç« å°†å…¨éƒ¨å›´ç»•è¯¥ä¸»é¢˜æ’°å†™ï¼Œä¸»é¢˜è¶Šç»†ï¼Œæ–‡ç« ä¹Ÿè¶Šè¯¦ç»†',
                                       value='')
            # å­˜å‚¨æ–‡ç« ä¸»é¢˜ä½œä¸ºæ ‡é¢˜ï¼Œç”¨äºå›¾ç‰‡ä¸‹è½½ç›®å½•
            if text_input:
                st.session_state['article_title'] = text_input
                
            # æ·»åŠ è‡ªå®šä¹‰ä¹¦å†™é£æ ¼çš„è¾“å…¥æ¡†
            custom_style = st.text_area(
                label='è‡ªå®šä¹‰ä¹¦å†™é£æ ¼å’Œè¦æ±‚', 
                help='åœ¨æ­¤è¾“å…¥ç‰¹å®šçš„å†™ä½œé£æ ¼å’Œè¦æ±‚ï¼Œå¦‚"å¹½é»˜é£è¶£"ã€"ä¸¥è°¨å­¦æœ¯"ã€"ç®€æ´æ˜äº†"ç­‰ï¼Œå°†å½±å“æ•´ç¯‡æ–‡ç« çš„é£æ ¼',
                placeholder='ä¾‹å¦‚ï¼šè¯·ä»¥å¹½é»˜é£è¶£çš„å£å»æ’°å†™ï¼Œå¤šä½¿ç”¨æ¯”å–»å’Œç”ŸåŠ¨çš„ä¾‹å­',
                height=100,
                key='custom_style'
            )
            # å»æ‰å†™ä½œæ¨¡å¼é€‰é¡¹ï¼Œå§‹ç»ˆä½¿ç”¨è¯¦ç»†æ¨¡å¼
            spider_num = st.slider(label='çˆ¬å–ç½‘é¡µæ•°é‡', help='ï¼ˆé»˜è®¤5ï¼Œæ•°é‡è¶Šå¤šæ—¶é—´è¶Šé•¿ï¼)', min_value=1, max_value=25, key=3,
                               value=15)
            # Use the checkbox directly without assigning to session_state
            convert_to_simple = st.checkbox("è½¬æ¢ç™½è¯æ–‡", key="convert_to_simple", value=False)
            convert_to_webpage = st.checkbox("è½¬æ¢ä¸ºBentoé£æ ¼ç½‘é¡µ", key="convert_to_webpage", value=False)

            # å›¾ç‰‡åˆ†æä¸æ’å…¥é€‰é¡¹æ”¾åœ¨è¡¨å•å†…æœ€ä¸‹æ–¹
            st.subheader("å›¾ç‰‡è®¾ç½®")
            col1, col2 = st.columns(2)
            with col1:
                st.session_state['enable_images'] = st.checkbox("è‡ªåŠ¨æ’å…¥ç›¸å…³å›¾ç‰‡", value=False)
            
            # åªæœ‰å½“å¯ç”¨å›¾ç‰‡æ—¶æ‰æ˜¾ç¤ºä¸‹è½½é€‰é¡¹
            with col2:
                st.session_state['download_images'] = st.checkbox("å›¾ç‰‡ä¸‹è½½è‡³æœ¬åœ°", value=False)
            st.info("ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å¼è‡ªåŠ¨æ’å…¥ç›¸å…³å›¾ç‰‡ï¼Œæ— éœ€é¢å¤–è®¾ç½®")
            submit_button = st.form_submit_button(label='æ‰§è¡Œ', disabled=st.session_state.run_status)

    st.caption('SuperWriter by WuXiaokun. ')
    st.subheader("è¶…çº§å†™æ‰‹ğŸ¤–", divider='rainbow')
    
    # åˆå§‹åŒ–æ ‡ç­¾é¡µç´¢å¼•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é»˜è®¤ä¸º0ï¼ˆmain_tabï¼‰
    if 'tab_index' not in st.session_state:
        st.session_state.tab_index = 0
    
    # å®šä¹‰æ ‡ç­¾é¡µåˆ‡æ¢å›è°ƒå‡½æ•°
    def tab_callback():
        # æ›´æ–°session_stateä¸­çš„tab_index
        st.session_state.tab_index = st.session_state.tabs
    
    # ä½¿ç”¨radioç»„ä»¶æ¨¡æ‹Ÿtabsï¼Œå› ä¸ºå®ƒå¯ä»¥ä¿æŒçŠ¶æ€
    # ä½¿ç”¨æ°´å¹³æ’åˆ—å’Œæœ€å°åŒ–æ ·å¼ä½¿å…¶çœ‹èµ·æ¥åƒtabs
    st.session_state.tabs = st.radio(
        "é€‰æ‹©åŠŸèƒ½",
        options=[0, 1],
        format_func=lambda x: "å†™ä½œ" if x == 0 else "æ–‡ç« å†åˆ›ä½œ",
        index=st.session_state.tab_index,
        on_change=tab_callback,
        horizontal=True,
        label_visibility="collapsed"
    )
    
    # æ ¹æ®é€‰æ‹©çš„æ ‡ç­¾é¡µæ˜¾ç¤ºç›¸åº”å†…å®¹
    if st.session_state.tabs != 0:
        # è½¬æ¢æ ‡ç­¾é¡µå†…å®¹
        transform_article.main()
        # æå‰è¿”å›ï¼Œä¸æ˜¾ç¤ºä¸»æ ‡ç­¾é¡µå†…å®¹
        return

    # ä¸»æ ‡ç­¾é¡µå†…å®¹ï¼Œç°åœ¨ç›´æ¥æ”¾åœ¨è¿™é‡Œ
    st.info("""

            ğŸ†•ç®€ä»‹ï¼šæœ¬åº”ç”¨æ˜¯åˆ©ç”¨LLM+æœç´¢å¼•æ“+çˆ¬è™«å¼€å‘çš„è‡ªåŠ¨æ’°å†™æ–‡ç« çš„æœºå™¨äººï¼Œåªéœ€è¦å¡«å†™æ–‡ç« ä¸»é¢˜,ç¨‹åºä¼šè‡ªåŠ¨ä¹¦å†™å¤§çº²å¹¶é€ä¸€æ’°å†™æ–‡ç« ã€‚

            âš ï¸æ³¨æ„ï¼šåœ¨å·¦ä¾§å¡«å†™æ–‡ç« ä¸»é¢˜åï¼Œç‚¹å‡»æ‰§è¡ŒæŒ‰é’®ï¼Œæ•´ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦5åˆ†é’Ÿ-30åˆ†é’Ÿä¸åˆ°ï¼Œç‚¹å‡»æ‰§è¡Œåè¯·ä¸è¦å…³é—­æœ¬é¡µé¢ï¼Œç­‰å¾…å®Œæˆåä¸‹è½½æ–‡ç« ï¼Œåˆ·æ–°æˆ–å…³é—­å°†ä¸ä¼šä¿å­˜ã€‚

            1. æ¨¡å‹é»˜è®¤deepseekï¼Œæ•ˆæœæœ€å¥½ï¼Œé€Ÿåº¦æœ€å¿«ï¼Œè¯¥é€‰é¡¹å¯ä»¥ä¸ç”¨ä¿®æ”¹ã€‚
            2. å¡«å†™æ–‡ç« ä¸»é¢˜ä¸ºä½ æƒ³è¦æ’°å†™çš„æ–‡ç« ä¸»é¢˜
            3. çˆ¬å–ç½‘é¡µæ•°é‡é»˜è®¤ä¸º15ï¼Œæ•°é‡è¶Šå¤šæ—¶é—´è¶Šé•¿ï¼ç³»ç»Ÿä¼šè‡ªåŠ¨æœç´¢å¹¶çˆ¬å–ç½‘é¡µå†…å®¹ã€‚

            """)

    # Initialize variables
    search_result = []
    outline_summary = ""
    outline_summary_json = {"title": "", "summary": "", "content_outline": []}
    outlines = ""
    article_content = ''

    if submit_button:
        # è®¾ç½®è¿è¡ŒçŠ¶æ€ä¸ºTrueï¼Œé˜²æ­¢é‡å¤æäº¤
        st.session_state.run_status = True
        # ä½¿ç”¨å•ç‹¬çš„å®¹å™¨æ¥æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯ï¼Œé¿å…ä¸å…¶ä»–å…ƒç´ é‡å 
        st.markdown("### å¤„ç†è¿›åº¦")
        progress_container = st.container()
        
        # åˆå§‹åŒ–å·²ä½¿ç”¨å›¾ç‰‡çš„é›†åˆï¼Œç”¨äºè·Ÿè¸ªå·²æ’å…¥çš„å›¾ç‰‡
        if 'used_images' not in st.session_state:
            st.session_state.used_images = set()
        else:
            # æ¯æ¬¡æ‰§è¡Œæ—¶é‡ç½®å·²ä½¿ç”¨å›¾ç‰‡é›†åˆ
            st.session_state.used_images = set()
        
        # é¦–å…ˆåˆ é™¤ç£ç›˜ä¸Šçš„FAISSç´¢å¼•æ–‡ä»¶
        try:
            if os.path.exists('data/faiss/index.faiss'):
                os.remove('data/faiss/index.faiss')
                logger.info("å·²åˆ é™¤FAISSç´¢å¼•æ–‡ä»¶")
            if os.path.exists('data/faiss/index_data.pkl'):
                os.remove('data/faiss/index_data.pkl')
                logger.info("å·²åˆ é™¤FAISSæ•°æ®æ–‡ä»¶")
        except Exception as e:
            logger.error(f"åˆ é™¤FAISSç´¢å¼•æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # è®¾ç½®å¼ºåˆ¶æ¸…ç©ºç´¢å¼•çš„æ ‡å¿—
        st.session_state.should_clear_index = True
        
        # æ¸…é™¤ç¼“å­˜å¹¶é‡æ–°åˆ›å»ºç©ºç´¢å¼•
        try:
            # å¼ºåˆ¶æ¸…é™¤ç¼“å­˜
            get_cached_resources.clear()
            
            # è·å–æ–°çš„ç©ºç´¢å¼• - è¿™å°†è§¦å‘get_cached_resourcesä¸­çš„æ¸…é™¤é€»è¾‘
            cached_faiss_index, _ = get_cached_resources(force_refresh=True)
            
            # ç¡®ä¿ç´¢å¼•ä¸ºç©º
            if cached_faiss_index:
                cached_faiss_index.clear()
                logger.info("æ‰§è¡ŒæŒ‰é’®ç‚¹å‡»ï¼šæˆåŠŸæ¸…ç©ºFAISSç´¢å¼•")
                
                # éªŒè¯ç´¢å¼•æ˜¯å¦çœŸçš„ä¸ºç©º
                index_size = cached_faiss_index.get_size()
                logger.info(f"æ¸…ç©ºåéªŒè¯ç´¢å¼•å¤§å°: {index_size}")
                
                if index_size > 0:
                    logger.warning(f"è­¦å‘Šï¼šFAISSç´¢å¼•æ¸…ç©ºåä»æœ‰ {index_size} ä¸ªé¡¹ç›®")
        except Exception as e:
            logger.error(f"æ¸…ç©ºFAISSç´¢å¼•å¤±è´¥: {str(e)}")
        
        # å…ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œç„¶åå†æ˜¾ç¤ºå…¶ä»–å†…å®¹
        progress_bar = progress_container.progress(0, text="Operation in progress. Please wait.")
        
        # ä½¿ç”¨æ›´æ¸…æ™°çš„å¸ƒå±€åˆ†å‰²
        col_left, col_right = st.columns([3, 2])
        
        # Left column: crawling, search details, outline generation, outline merging
        with col_left:
            st.subheader("å¤„ç†è¿‡ç¨‹")
            # Crawl web content
            progress_bar.progress(10, text="Spider in progress. Please wait...")
            with st.status("æŠ“å–ç½‘é¡µå†…å®¹"):
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    # æ£€æŸ¥æ˜¯å¦å¯ç”¨å›¾ç‰‡åŠŸèƒ½ï¼Œå¦‚æœå¯ç”¨åˆ™ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å¼
                    is_multimodal = st.session_state.get('enable_images', False)
                    future = executor.submit(Search(result_num=spider_num).get_search_result, text_input, is_multimodal=is_multimodal, theme=text_input)
                    for future in concurrent.futures.as_completed([future]):
                        search_result = future.result()
            with st.popover("æŸ¥çœ‹æœç´¢è¯¦ç»†..."):
                for item in search_result:
                    st.markdown(f"æ ‡é¢˜ï¼š{item.get('title')}  é“¾æ¥ï¼š{item.get('url')}")
            
            # æ˜¾ç¤ºå½“å‰FAISSç´¢å¼•ä¸­çš„æ‰€æœ‰å›¾ç‰‡
            if st.session_state.get('enable_images', False):
                # ä½¿ç”¨ç¼“å­˜çš„FAISSç´¢å¼•å®ä¾‹ï¼Œä½†ä¸å¼ºåˆ¶åˆ·æ–°ä»¥é¿å…åˆ é™¤ç´¢å¼•
                cached_faiss_index, _ = get_cached_resources(force_refresh=False)
                index_size = cached_faiss_index.get_size()
                
                with st.popover(f"æŸ¥çœ‹å·²æŠ“å–çš„å›¾ç‰‡ ({index_size})"):
                    if index_size == 0:
                        st.warning("å½“å‰æ²¡æœ‰å¯ç”¨çš„å›¾ç‰‡æ•°æ®")
                    else:
                        # ä»FAISSç´¢å¼•è·å–æ‰€æœ‰çš„å›¾ç‰‡æ•°æ®
                        all_data = cached_faiss_index.get_all_data()
                        
                        # åˆ›å»ºä¸‰åˆ—å¸ƒå±€æ˜¾ç¤ºå›¾ç‰‡
                        cols = st.columns(3)
                        for i, item in enumerate(all_data):
                            # æ£€æŸ¥æ•°æ®æ ¼å¼ï¼Œå¤„ç†å­—å…¸ç»“æ„
                            if isinstance(item, dict):
                                img_url = item.get('image_url', '')
                                description = item.get('description', '')
                            else:
                                # å‡è®¾å…¬å¸å¯èƒ½ä¸ä¸€å®šç”¨å®Œå…¨ä¸€æ ·çš„æ•°æ®ç»“æ„
                                # å°è¯•å…¼å®¹æ—§æ ¼å¼
                                try:
                                    img_url, description = item
                                except:
                                    st.warning(f"\u8df3è¿‡ä¸å…¼å®¹çš„å›¾ç‰‡æ•°æ®æ ¼å¼: {str(item)[:100]}")
                                    continue
                            
                            # ç”¨äºè°ƒè¯•
                            # st.write(f"\u56feç‰‡ç´¢å¼• {i}: {img_url}")
                            
                            # è½®æµä½¿ç”¨ä¸åŒåˆ—æ˜¾ç¤ºå›¾ç‰‡
                            with cols[i % 3]:
                                try:
                                    # æ˜¾ç¤ºå›¾ç‰‡
                                    st.image(img_url, width=150)
                                    # æ˜¾ç¤ºæè¿°ï¼ˆæˆªæ–­è¿‡é•¿çš„æè¿°ï¼‰
                                    max_desc_len = 100
                                    short_desc = description if len(description) <= max_desc_len else f"{description[:max_desc_len]}..."
                                    st.caption(short_desc)
                                except Exception as e:
                                    st.error(f"æ— æ³•åŠ è½½å›¾ç‰‡: {str(e)}")

            # Generate outline
            progress_bar.progress(30, text="Spider Down! Now generate the outline...")
            with st.status("ç”Ÿæˆå¤§çº²"):
                try:
                    outlines = llm_task(search_result, text_input, pt.ARTICLE_OUTLINE_GEN, model_type=model_type, model_name=model_name)
                except ConnectionError as e:
                    st.error(f"é”™è¯¯: {str(e)}")
                    st.stop()

            # Merge outline if needed
            progress_bar.progress(60, text="Integrate article outline...")
            with st.status("èåˆå¤§çº²"):
                try:
                    # æ£€æŸ¥æ˜¯å¦åªæœ‰ä¸€æ¡å¤§çº²æ•°æ®
                    if isinstance(outlines, str) and outlines.count("title") <= 1:
                        # åªæœ‰ä¸€æ¡å¤§çº²æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
                        outline_summary = outlines
                    else:
                        # æœ‰å¤šæ¡å¤§çº²æ•°æ®ï¼Œè¿›è¡Œèåˆ
                        outline_summary = chat(f'<topic>{text_input}</topic> <content>{outlines}</content>', 
                                                pt.ARTICLE_OUTLINE_SUMMARY, 
                                                model_type=model_type, 
                                                model_name=model_name)
                except ConnectionError as e:
                    st.error(f"é”™è¯¯: {str(e)}")
                    st.stop()

            # Parse outline JSON
            outline_summary_json = parse_outline_json(outline_summary, text_input)
            outline_summary_json.setdefault('title', text_input)
            outline_summary_json.setdefault('summary', "")
            outline_summary_json.setdefault('content_outline', [])

        # Right column: outline preview
        with col_right:
            st.subheader("å¤§çº²é¢„è§ˆ")
            if outline_summary_json.get('content_outline'):
                with st.popover("æŸ¥çœ‹å¤§çº²"):
                    st.json(outline_summary_json)
                
                # ä½¿ç”¨æ›´æ¸…æ™°çš„æ ¼å¼æ˜¾ç¤ºæ ‡é¢˜å’Œæ‘˜è¦
                st.markdown(f"### {outline_summary_json['title']}")
                st.markdown(f"> {outline_summary_json['summary']}")
                    
                    

        # *************************** ä¹¦å†™æ–‡ç«  *************************
        if 'content_outline' in outline_summary_json and outline_summary_json['content_outline']:
            repeat_num = len(outline_summary_json['content_outline'])
            my_bar_article_start = 100 - repeat_num*2
            progress_bar.progress(my_bar_article_start, text="Writing article...")
        with st.spinner("ä¹¦å†™æ–‡ç« ..."):
            n = 1
            # Reset article_content if it's already in the submit_button block
            article_content = ''
            if 'content_outline' in outline_summary_json and outline_summary_json['content_outline']:
                for outline_block in outline_summary_json['content_outline']:
                    progress_bar.progress(my_bar_article_start + n*2, text=f"æ­£åœ¨æ’°å†™  {outline_block['h1']}  {n}/{repeat_num}")
                
                    # æ ¹æ®æŠ“å–çš„å†…å®¹èµ„æ–™ç”Ÿæˆå†…å®¹
                    # ç¡®å®šæ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†ç¬¬ä¸€ç« ï¼ˆä¸åŒ…å«æ ‡é¢˜ï¼‰
                    is_first_chapter = n == 1
                    
                    # æ„å»ºé—®é¢˜ï¼Œç¬¬ä¸€ç« ç‰¹æ®Šå¤„ç†
                    title_instruction = 'ï¼Œæ³¨æ„ä¸è¦åŒ…å«ä»»ä½•æ ‡é¢˜ï¼Œç›´æ¥å¼€å§‹æ­£æ–‡å†…å®¹ï¼Œæœ‰å¸å¼•åŠ›å¼€å¤´ï¼ˆç—›ç‚¹/æ‚¬å¿µï¼‰ï¼Œç”ŸåŠ¨å½¢è±¡ï¼Œé£è¶£å¹½é»˜ï¼' if is_first_chapter else ''
                    question = f'<å®Œæ•´å¤§çº²>{outline_summary}</å®Œæ•´å¤§çº²> è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯ï¼Œä¹¦å†™å‡ºä»¥ä¸‹å†…å®¹ >>> {outline_block} <<<{title_instruction}'
                    
                    # è·å–å†…å®¹å—
                    outline_block_content = llm_task(search_result, question=question,
                                                  output_type=pt.ARTICLE_OUTLINE_BLOCK, model_type=model_type, model_name=model_name)
                    
                    # è·å–è‡ªå®šä¹‰é£æ ¼å¹¶åº”ç”¨åˆ°promptä¸­
                    custom_prompt = pt.ARTICLE_OUTLINE_BLOCK
                    if 'custom_style' in st.session_state and st.session_state.custom_style.strip():
                        # åœ¨åŸæœ‰promptåŸºç¡€ä¸Šæ·»åŠ è‡ªå®šä¹‰é£æ ¼è¦æ±‚
                        custom_prompt = custom_prompt.replace('---è¦æ±‚---', f'---è¦æ±‚---\n        - {st.session_state.custom_style}')
                    
                    # æ„å»ºæœ€ç»ˆæç¤ºï¼Œç¬¬ä¸€ç« ç‰¹æ®Šå¤„ç†
                    final_instruction = 'ï¼Œæ³¨æ„ä¸è¦åŒ…å«ä»»ä½•æ ‡é¢˜ï¼ˆä¸è¦åŒ…å«h1å’Œh2æ ‡é¢˜ï¼‰ï¼Œç›´æ¥å¼€å§‹æ­£æ–‡å†…å®¹' if is_first_chapter else ''
                    outline_block_content_final = chat(
                        f'<å®Œæ•´å¤§çº²>{outline_summary}</å®Œæ•´å¤§çº²> <ç›¸å…³èµ„æ–™>{outline_block_content}</ç›¸å…³èµ„æ–™> è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯ï¼Œä¹¦å†™å¤§çº²ä¸­çš„ä»¥ä¸‹è¿™éƒ¨åˆ†å†…å®¹ï¼š{outline_block}{final_instruction}',
                        custom_prompt, model_type=model_type, model_name=model_name)
            
                    # ä½¿ç”¨å•ç‹¬çš„å®¹å™¨æ¥æ˜¾ç¤ºå†…å®¹å—ï¼Œé¿å…é‡å 
                    content_container = st.container()
                    with content_container:
                        with st.expander(f'{outline_block["h1"]} {n}/{repeat_num}', expanded=True):
                            st.markdown(f"""
                            {outline_block_content_final}
                            """)
                    n += 1
                    # æ·»åŠ åˆ†éš”çº¿æ¥åŒºåˆ†å†…å®¹å—
                    st.markdown("---")
                
                    # å¦‚æœå¯ç”¨äº†å¤šæ¨¡æ€å›¾åƒå¤„ç†ï¼Œå°è¯•ä¸ºå½“å‰å†…å®¹å—æ‰¾åˆ°ç›¸å…³å›¾ç‰‡
                    if st.session_state.get('enable_images', False):
                        try:
                            from utils.embedding_utils import search_similar_text
                            
                            # ä½¿ç”¨æ–‡ç« å†…å®¹å—æŸ¥æ‰¾ç›¸å…³å›¾ç‰‡
                            similarity_threshold = 0.15  # é™ä½é˜ˆå€¼ä»¥å¢åŠ åŒ¹é…æˆåŠŸç‡
                            
                            # ä½¿ç”¨ç¼“å­˜çš„FAISSç´¢å¼•å®ä¾‹ï¼Œä½†ä¸å¼ºåˆ¶åˆ·æ–°ä»¥é¿å…åˆ é™¤ç´¢å¼•
                            cached_faiss_index, _ = get_cached_resources(force_refresh=False)
                            
                            # è¾“å‡ºç´¢å¼•å¤§å°ï¼Œå¸®åŠ©è°ƒè¯•
                            index_size = cached_faiss_index.get_size()
                            logger.info(f"å½“å‰FAISSç´¢å¼•å¤§å°: {index_size}")
                            
                            if index_size == 0:
                                # å†å°è¯•ä¸€æ¬¡åŠ è½½ï¼Œå¯èƒ½åœ¨è¿è¡Œè¿‡ç¨‹ä¸­æœ‰æ–°çš„å›¾ç‰‡è¢«å¤„ç†
                                import time
                                logger.warning("ç­‰å¾…3ç§’å¹¶é‡è¯•åŠ è½½FAISSç´¢å¼•...")
                                time.sleep(3)  # ç­‰å¾…å‡ ç§’é’Ÿï¼Œç¡®ä¿ä»»ä½•æ­£åœ¨è¿›è¡Œçš„ä¿å­˜æ“ä½œéƒ½å·²å®Œæˆ
                                # ä»ç„¶ä¸ä½¿ç”¨force_refresh=Trueï¼Œå› ä¸ºè¿™å¯èƒ½åˆ é™¤ç´¢å¼•
                                cached_faiss_index, _ = get_cached_resources(force_refresh=False)
                                index_size = cached_faiss_index.get_size()
                                logger.info(f"é‡è¯•åçš„FAISSç´¢å¼•å¤§å°: {index_size}")
                                
                                if index_size == 0:
                                    st.warning("FAISSç´¢å¼•ä¸­æ²¡æœ‰å›¾ç‰‡æ•°æ®ï¼Œæ— æ³•è¿›è¡Œå›¾ç‰‡åŒ¹é…")
                                    continue
                                
                            # æœç´¢ç›¸ä¼¼çš„å›¾ç‰‡æè¿°
                            # å¢åŠ æœç´¢ç»“æœæ•°é‡ï¼Œæé«˜åŒ¹é…æˆåŠŸç‡
                            # å¢åŠ kå€¼ä»¥è·å–æ›´å¤šå€™é€‰å›¾ç‰‡ï¼Œå› ä¸ºéƒ¨åˆ†å›¾ç‰‡å¯èƒ½å·²è¢«ä½¿ç”¨
                            # è·å–å½“å‰å¤§çº²çš„h1å’Œh2ç»„è£…æˆå­—ç¬¦ä¸²è¿›è¡Œæœç´¢
                            outline_block_str = outline_block['h1'] + "".join([h2 for h2 in outline_block['h2']]) + outline_block_content_final
                            _, distances, matched_data = search_similar_text(outline_block_str, cached_faiss_index, k=10)
                            
                            # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°ç›¸å…³å›¾ç‰‡
                            if matched_data and len(matched_data) > 0:
                                image_inserted = False
                                inserted_image_count = 0  # åˆå§‹åŒ–å·²æ’å…¥å›¾ç‰‡è®¡æ•°å™¨
                                
                                # éå†æ‰€æœ‰åŒ¹é…ç»“æœï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆä¸”æœªä½¿ç”¨çš„å›¾ç‰‡
                                for i, (distance, data) in enumerate(zip(distances, matched_data)):
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ•°æ®
                                    if isinstance(data, dict) and 'image_url' in data:
                                        # è·å–å›¾ç‰‡URL
                                        image_url = data['image_url']
                                        
                                        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å·²è¢«ä½¿ç”¨
                                        if image_url in st.session_state.used_images:
                                            logger.info(f"è·³è¿‡å·²ä½¿ç”¨çš„å›¾ç‰‡: {image_url[:50]}...")
                                            continue
                                            
                                        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•° (1 - æ ‡å‡†åŒ–è·ç¦»)
                                        similarity = 1.0 - min(distance / 2.0, 0.99)  # æ ‡å‡†åŒ–å¹¶åè½¬
                                        
                                        # åªåœ¨ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼æ—¶æ’å…¥å›¾ç‰‡
                                        if similarity >= similarity_threshold:
                                            # å°†å›¾ç‰‡URLæ·»åŠ åˆ°å·²ä½¿ç”¨é›†åˆ
                                            st.session_state.used_images.add(image_url)
                                            
                                            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°
                                            local_image_path = None
                                            if st.session_state.get('download_images', False):
                                                # è·å–æ–‡ç« æ ‡é¢˜ä½œä¸ºç›®å½•å
                                                article_title = st.session_state.get('article_title', 'untitled')
                                                save_dir = get_image_save_directory(article_title)
                                                
                                                # ä¸‹è½½å›¾ç‰‡
                                                local_image_path = download_image(image_url, save_dir)
                                           
                                            image_markdown = f"![å›¾ç‰‡]({image_url})\n\n"
                                            
                                            # å°†å›¾ç‰‡æ’å…¥åˆ°å†…å®¹å—å‰
                                            outline_block_content_final = image_markdown + outline_block_content_final
                                            logger.info(f"æˆåŠŸåŒ¹é…å›¾ç‰‡ï¼Œç›¸ä¼¼åº¦: {similarity:.4f}ï¼Œå·²ä½¿ç”¨å›¾ç‰‡æ•°: {len(st.session_state.used_images)}")
                                            
                                            # ä½¿ç”¨ä¸€ä¸ªå°çš„å®¹å™¨æ¥æ˜¾ç¤ºä¿¡æ¯ï¼Œé¿å…å½±å“ä¸»è¦å†…å®¹å¸ƒå±€
                                            with st.container():
                                                st.info(f"ä¸ºå½“å‰å†…å®¹å—æ’å…¥äº†ç›¸å…³å›¾ç‰‡ (ç›¸ä¼¼åº¦: {similarity:.2f})")
                                                st.image(image_url)
                                                
                                            image_inserted = True
                                            
                                            # è®¡æ•°å·²æ’å…¥çš„å›¾ç‰‡æ•°é‡
                                            inserted_image_count += 1
                                            
                                            # å¦‚æœå·²ç»æ’å…¥äº†2å¼ å›¾ç‰‡ï¼Œåˆ™è·³å‡ºå¾ªç¯
                                            if inserted_image_count >= 2:
                                                logger.info(f"å·²ä¸ºå½“å‰å†…å®¹å—æ’å…¥2å¼ å›¾ç‰‡ï¼Œåœæ­¢æœç´¢æ›´å¤šå›¾ç‰‡")
                                                break
                                            
                                if not image_inserted:
                                    logger.warning(f"æœªæ‰¾åˆ°åˆé€‚çš„æœªä½¿ç”¨å›¾ç‰‡ï¼Œå·²ä½¿ç”¨å›¾ç‰‡æ•°: {len(st.session_state.used_images)}")
                                    # å¯ä»¥é€‰æ‹©åœ¨è¿™é‡Œæ·»åŠ ä¸€ä¸ªæç¤ºï¼Œå‘ŠçŸ¥ç”¨æˆ·æœªæ‰¾åˆ°åˆé€‚çš„å›¾ç‰‡
                        except Exception as e:
                            st.warning(f"æŸ¥æ‰¾ç›¸å…³å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")
                    
                    # æ·»åŠ æ¢è¡Œç¬¦ï¼Œç¡®ä¿æ¯ä¸ªéƒ¨åˆ†ä¹‹é—´æœ‰é€‚å½“çš„åˆ†éš”
                    article_content += outline_block_content_final + '\n\n'
            # *************************** è‡ªåŠ¨ä¿å­˜åŸå§‹æ–‡ç« åˆ°å†å²è®°å½• *************************
            # æ›´æ–°è¿›åº¦æ¡åˆ°100%ï¼Œè¡¨ç¤ºæ–‡ç« å·²å®Œæˆ
            progress_bar.progress(100, text="æ–‡ç« ç”Ÿæˆå®Œæˆï¼")
            
            original_article_id = None
            if article_content.strip():
                # æ–‡ç« ç”Ÿæˆå®Œæˆåï¼Œé‡ç½®è¿è¡ŒçŠ¶æ€ï¼Œå…è®¸å†æ¬¡æäº¤
                st.session_state.run_status = False
                current_user = get_current_user()
                if current_user:
                    custom_style = st.session_state.get('custom_style', '')
                    # Record image parameters if enabled
                    image_enabled = st.session_state.get('enable_images', False)
                    
                    original_record = add_history_record(
                        current_user, 
                        outline_summary_json['title'], 
                        article_content, 
                        summary=outline_summary_json.get('summary', ''), 
                        model_type=model_type, 
                        model_name=model_name, 
                        spider_num=spider_num, 
                        custom_style=custom_style,
                        is_transformed=False,
                        image_enabled=image_enabled,
                    )
                    original_article_id = original_record.get('id')
                    st.success(f"åŸå§‹æ–‡ç« å·²è‡ªåŠ¨ä¿å­˜åˆ°å†å²è®°å½•ä¸­ã€‚")
                    # åˆ é™¤faissç´¢å¼•
                    try:
                        if os.path.exists('data/faiss/index.faiss'):
                            os.remove('data/faiss/index.faiss')
                        if os.path.exists('data/faiss/index_data.pkl'):
                            os.remove('data/faiss/index_data.pkl')
                        logger.info("æ–‡ç« ç”Ÿæˆå®ŒæˆåæˆåŠŸåˆ é™¤FAISSç´¢å¼•æ–‡ä»¶")
                    except Exception as e:
                        logger.error(f"åˆ é™¤FAISSç´¢å¼•æ–‡ä»¶å¤±è´¥: {str(e)}")

            # *************************** è½¬æ¢ç™½è¯æ–‡å¹¶ä¿å­˜ *************************
            if convert_to_simple and article_content.strip() and original_article_id is not None:
                transformed_article_content = ""
                with st.status("æ­£åœ¨è½¬æ¢ç™½è¯æ–‡..."):
                    try:
                        transformed_article_content = chat(article_content, pt.CONVERT_2_SIMPLE, model_type=model_type, model_name=model_name)
                        st.success("ç™½è¯æ–‡è½¬æ¢å®Œæˆï¼")
                    except ConnectionError as e:
                        st.error(f"ç™½è¯æ–‡è½¬æ¢é”™è¯¯: {str(e)}")
                    except Exception as e:
                        st.error(f"ç™½è¯æ–‡è½¬æ¢å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
                
                if transformed_article_content.strip(): # Save only if transformation was successful
                    current_user = get_current_user() # Re-get user just in case
                    if current_user:
                        custom_style = st.session_state.get('custom_style', '')
                        # Find the transformation name for CONVERT_2_SIMPLE from settings
                        transformation_name_for_simple = "ç™½è¯æ–‡" # Default fallback
                        for name, prompt_template in ARTICLE_TRANSFORMATIONS.items():
                            if prompt_template == pt.CONVERT_2_SIMPLE:
                                transformation_name_for_simple = name
                                break
                        
                        add_history_record(
                            current_user, 
                            f"{outline_summary_json['title']} ({transformation_name_for_simple})", 
                            transformed_article_content, 
                            summary=f"{outline_summary_json.get('summary', '')} ({transformation_name_for_simple} ç‰ˆæœ¬)", 
                            model_type=model_type, 
                            model_name=model_name, 
                            spider_num=spider_num, 
                            custom_style=custom_style,
                            is_transformed=True,
                            original_article_id=original_article_id
                        )
                        article_content = transformed_article_content # Update article_content to the transformed version for download
                        st.success(f"{transformation_name_for_simple} ç‰ˆæœ¬å·²è‡ªåŠ¨ä¿å­˜åˆ°å†å²è®°å½•ä¸­ã€‚")
            elif convert_to_simple and not article_content.strip():
                st.warning("åŸå§‹æ–‡ç« å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç™½è¯æ–‡è½¬æ¢ã€‚")
            elif convert_to_simple and original_article_id is None:
                st.warning("æœªèƒ½ä¿å­˜åŸå§‹æ–‡ç« ï¼Œæ— æ³•è¿›è¡Œç™½è¯æ–‡è½¬æ¢å¹¶å…³è”ã€‚")
            
            # *************************** ç‚¹å‡»ä¸‹è½½æ–‡ç«  *************************
            st.download_button(
                label="ä¸‹è½½æ–‡ç« ",
                data=article_content,
                file_name=f"{outline_summary_json['title']}.md",
                mime="text/markdown",
                key="download_generated_article"
            )
            
            # *************************** è½¬æ¢ä¸ºBentoé£æ ¼ç½‘é¡µå¹¶ä¿å­˜ *************************
            if st.session_state.get('convert_to_webpage', False) and article_content.strip() and original_article_id is not None:
                webpage_content = ""
                with st.status("æ­£åœ¨è½¬æ¢ä¸ºBentoé£æ ¼ç½‘é¡µ..."):
                    try:
                        # ä½¿ç”¨æ–°çš„Promptæ¨¡æ¿ç”Ÿæˆç½‘é¡µå†…å®¹
                        webpage_content = chat(f"é™„ä»¶æ–‡æ¡£å†…å®¹:\n\n{article_content}", pt.BENTO_WEB_PAGE, model_type=model_type, model_name=model_name)
                        st.success("Bentoé£æ ¼ç½‘é¡µè½¬æ¢å®Œæˆï¼")
                    except ConnectionError as e:
                        st.error(f"ç½‘é¡µè½¬æ¢é”™è¯¯: {str(e)}")
                    except Exception as e:
                        st.error(f"ç½‘é¡µè½¬æ¢å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
                
                if webpage_content.strip(): # ä»…åœ¨è½¬æ¢æˆåŠŸæ—¶æ‰§è¡Œ
                    current_user = get_current_user()
                    if current_user:
                        transformation_name_for_webpage = "Bentoç½‘é¡µ"
                        
                        # ä¿å­˜åˆ°å†å²è®°å½•
                        # ä»åŸå§‹æ–‡ç« è®°å½•ä¸­è·å–å›¾ç‰‡ç›¸å…³å‚æ•°
                        # é¦–å…ˆåŠ è½½åŸå§‹æ–‡ç« çš„è®°å½•
                        history = load_user_history(current_user)
                        original_record = None
                        for record in history:
                            if record.get('id') == original_article_id:
                                original_record = record
                                break
                        
                        # è·å–åŸå§‹æ–‡ç« çš„å›¾ç‰‡å‚æ•°
                        image_enabled = original_record.get('image_enabled', False) if original_record else False
                        # ä¸å†éœ€è¦è®°å½•task_idå’Œé˜ˆå€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        image_task_id = None
                        image_similarity_threshold = 0.5 if image_enabled else None
                        image_max_count = 10 if image_enabled else None
                        
                        add_history_record(
                            current_user, 
                            f"{outline_summary_json['title']} ({transformation_name_for_webpage})", 
                            webpage_content, 
                            summary=f"{outline_summary_json.get('summary', '')} ({transformation_name_for_webpage} ç‰ˆæœ¬)", 
                            model_type=model_type, 
                            model_name=model_name, 
                            spider_num=spider_num, 
                            custom_style=custom_style,
                            is_transformed=True,
                            original_article_id=original_article_id,
                            image_task_id=image_task_id,
                            image_enabled=image_enabled,
                            image_similarity_threshold=image_similarity_threshold,
                            image_max_count=image_max_count
                        )
                        st.success(f"{transformation_name_for_webpage} ç‰ˆæœ¬å·²è‡ªåŠ¨ä¿å­˜åˆ°å†å²è®°å½•ä¸­ã€‚")

                        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                        html_filename = f"{outline_summary_json['title'].replace(' ', '_')}.html"
                        
                        # å¯¼å…¥ä¿å­˜HTMLçš„å‡½æ•°
                        from utils.history_utils import save_html_to_user_dir
                        
                        # è·å–å½“å‰ç”¨æˆ·
                        current_user = get_current_user()
                        
                        # ä¿å­˜HTMLå†…å®¹åˆ°æ–‡ä»¶å¹¶è·å–URLè·¯å¾„
                        _, url_path = save_html_to_user_dir(current_user, webpage_content, html_filename)
                        
                        # ç”Ÿæˆå¯è®¿é—®çš„URL
                        base_url = HTML_NGINX_BASE_URL  # æ ¹æ®nginxé…ç½®è°ƒæ•´
                        article_url = f"{base_url}{url_path}"

                        # æ˜¾ç¤ºé¢„è§ˆé“¾æ¥
                        st.markdown(f"[ç‚¹å‡»é¢„è§ˆç½‘é¡µæ•ˆæœ]({article_url})")

                        # æä¾›HTMLæ–‡ä»¶ä¸‹è½½
                        st.download_button(
                            label="ä¸‹è½½ç½‘é¡µæ–‡ä»¶",
                            data=webpage_content,
                            file_name=f"{outline_summary_json['title']}.html",
                            mime="text/html",
                            key="download_generated_webpage"
                        )

            elif st.session_state.get('convert_to_webpage', False) and not article_content.strip():
                st.warning("åŸå§‹æ–‡ç« å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç½‘é¡µè½¬æ¢ã€‚")
            elif st.session_state.get('convert_to_webpage', False) and original_article_id is None:
                st.warning("æœªèƒ½ä¿å­˜åŸå§‹æ–‡ç« ï¼Œæ— æ³•è¿›è¡Œç½‘é¡µè½¬æ¢å¹¶å…³è”ã€‚")

# Check if we need to rerun
if st.session_state.get('trigger_rerun', False):
    # Reset the flag
    st.session_state['trigger_rerun'] = False
    # è®¾ç½®rerunæ ‡å¿—ï¼Œç”¨äºåŒºåˆ†æ­£å¸¸é¡µé¢åŠ è½½å’Œrerun
    st.session_state['_is_rerun'] = True
    st.rerun()
else:
    # é‡ç½®rerunæ ‡å¿—
    st.session_state['_is_rerun'] = False
    # Call the main function
    main()